(1 - (a-1)^(n))/(2-a),
(1 - a + (a-1)^(n))/(2-a)
),2,byrow=TRUE)
Pn
Q %*% Lambda^4 %*% iQ
a <- 0.1
m <- c(a, 1-a,1,0)
P <- matrix(m,2,byrow=TRUE)
J <- matrix(c(1,0,0,a-1),2,byrow=TRUE)
S  <- matrix(c(1,a-1,1,1),2,byrow=TRUE)
iS <- matrix(c(1/(2-a),(a-1)/(a-2),1/(a-2),1/(2-a)),2,byrow=TRUE)
S %*% J %*% iS
P
S %*% J^4 %*% iS
P %*% P %*% P %*% P
a <- 0.1
m <- c(a, 1-a,1,0)
P <- matrix(m,2,byrow=TRUE)
Q
Q
c
c
n
P
Q
c1
c2
eigen(P)
c1
c2
J <- matrix(c(1,0,0,a-1),2,byrow=TRUE)
S  <- matrix(c(1,a-1,1,1),2,byrow=TRUE)
iS <- matrix(c(1/(2-a),(a-1)/(a-2),1/(a-2),1/(2-a)),2,byrow=TRUE)
S %*% J %*% iS
P
S %*% J^4 %*% iS
P %*% P %*% P %*% P
S %*% J^4 %*% iS
P %*% P %*% P %*% P
S %*% J %*% iS
P
library(faraway)
data(sexab,package="faraway")
sexab
#look at the variable for different groups
by(sexab,sexab$csa,summary)
?sexab
data(sexab,package="faraway")
sexab
#look at the variable for different groups
by(sexab,sexab$csa,summary)
#boxplot for categorical variable
plot(ptsd ~ csa, sexab)
plot(ptsd ~ cpa, pch=as.character(csa), sexab)
#t-test H_0: the two groups have equal mean
#equality of variances is also assumed
t.test(ptsd ~ csa, sexab, var.equal=TRUE)
#create dummy variables for factors
d1 <- ifelse(sexab$csa == "Abused",1,0)
d2 <- ifelse(sexab$csa == "NotAbused",1,0)
#boxplot for categorical variable
plot(ptsd ~ csa, sexab)
plot(ptsd ~ cpa, pch=as.character(csa), sexab)
#t-test H_0: the two groups have equal mean
#equality of variances is also assumed
t.test(ptsd ~ csa, sexab, var.equal=TRUE)
#create dummy variables for factors
d1 <- ifelse(sexab$csa == "Abused",1,0)
d2 <- ifelse(sexab$csa == "NotAbused",1,0)
#if we add them all to the linear model
# and together with a constant
lmod <- lm(ptsd ~ d1 + d2 , sexab)
sumary(lmod)
#we remove one variable, that will be the base that we compare other variable to
model.matrix(lmod)
lmod <- lm(ptsd ~ d2, sexab)
sumary(lmod)
#in this regression parameters are directly means of different groups
lmod <- lm(ptsd ~ d1 + d2 -1, sexab)
sumary(lmod)
lmod <- lm(ptsd ~ cpa + csa, sexab)
sumary(lmod)
abline(lmod$coeff[1],lmod$coeff[2])
abline(lmod$coeff[1]+lmod$coeff[3],lmod$coeff[2])
#we may want to recode the factor variable, so that the reference is picked
#(and not set according to alphabet)
class(sexab$csa)
sexab$csa <- relevel(sexab$csa, ref="NotAbused")
lmod <- lm(ptsd ~ csa, sexab)
sumary(lmod)
#interaction term?
lmod4 <- lm(ptsd ~ cpa+csa+cpa:csa,sexab)
sumary(lmod4)
model.matrix(lmod4)
plot(ptsd ~ cpa, sexab, pch=as.numeric(csa))
abline(3.96, 0.764)
abline(3.96+6.86, 0.764-0.314,lty=2)
lmod3 <- lm(ptsd ~ cpa+csa,sexab)
sumary(lmod3)
plot(ptsd ~ cpa, sexab, pch=as.numeric(csa))
abline(3.98, 0.551)
abline(3.98+6.27, 0.551, lty=2)
confint(lmod3)[3,]
plot(fitted(lmod3),residuals(lmod3),pch=as.numeric(sexab$csa),  xlab="Fitted",ylab="Residuals")
lmod1 <- lm(ptsd ~ cpa,sexab)
sumary(lmod1)
#centering is important in models with interactions!
data(whiteside,package="MASS")
require(ggplot2)
ggplot(aes(x=Temp,y=Gas),data=whiteside)+geom_point()+facet_grid(~ Insul)+geom_smooth(method="lm")
lmod <- lm(Gas ~ Temp*Insul, whiteside)
sumary(lmod)
mean(whiteside$Temp)
whiteside$ctemp <- whiteside$Temp - mean(whiteside$Temp)
lmodc <- lm(Gas ~ ctemp*Insul, whiteside)
sumary(lmodc)
?fruitfly
#sex-life of fruitflies
data(fruitfly,package="faraway")
plot(longevity ~ thorax, fruitfly, pch=unclass(activity))
legend(0.63,100,levels(fruitfly$activity),pch=1:5)
require(ggplot2)
ggplot(aes(x=thorax,y=longevity),data=fruitfly) + geom_point() + facet_wrap( ~ activity)
lmod <- lm(longevity ~ thorax*activity, fruitfly)
sumary(lmod)
model.matrix(lmod)
plot(lmod)
sumary(lmodp)
lmodp <- lm(longevity ~ thorax+activity, fruitfly)
drop1(lmodp,test="F")
sumary(lmodp)
library(MASS)
boxcox(lmodp)
plot(residuals(lmodp) ~ fitted(lmodp),pch=unclass(fruitfly$activity),  xlab="Fitted",ylab="Residuals")
abline(h=0)
#heteroscedasticity
lmodl <- lm(log(longevity) ~ thorax+activity, fruitfly)
plot(residuals(lmodl) ~ fitted(lmodl),pch=unclass(fruitfly$activity), xlab="Fitted",ylab="Residuals")
abline(h=0)
#much better
sumary(lmodl)
exp(coef(lmodl)[3:6])
#do we actually need thorax at all
lmodh <- lm(thorax ~ activity, fruitfly)
anova(lmodh)
#but...
lmodu <- lm(log(longevity) ~ activity, fruitfly)
sumary(lmodu)
#it will make our estimates more precise
exp(coef(lmodu)[2:5])
boxcox(lmodp)
#heteroscedasticity
lmodl <- lm(log(longevity) ~ thorax+activity, fruitfly)
plot(residuals(lmodl) ~ fitted(lmodl),pch=unclass(fruitfly$activity), xlab="Fitted",ylab="Residuals")
abline(h=0)
#much better
sumary(lmodl)
lmod <- lm(longevity ~ thorax*activity, fruitfly)
sumary(lmod)
#do we actually need thorax at all
lmodh <- lm(thorax ~ activity, fruitfly)
sumary(lmodh)
#221/6
#The dataset clot contains the clotting times of blood varying as percentage concentration
#of prothrombin-free plasma. There are two lots of thromboplastin.
data(clot)
summary(clot)
#221/6
#The dataset clot contains the clotting times of blood varying as percentage concentration
#of prothrombin-free plasma. There are two lots of thromboplastin.
data(clot)
summary(clot)
#(a) Plot the data using a different plotting symbol according to the lot.
plot(time ~ conc, pch=as.character(lot), clot)
lmod <- lm(time ~ conc, clot)
abline(lmod$coeff)
#(b) Find the transformation of the two continuous variables to form a linear relationship.
lmod <- lm(time ~ conc + lot, data = clot)
summary(lmod)
boxcox(lmod)
plot(I(1/time) ~ log(conc), pch=as.character(lot), clot)
lmod2 <- lm(I(1/time) ~ log(conc) + lot, data = clot)
clot$invTime <- 1/clot$time
lmod2 <- lm(invTime ~ log(conc) + lot, data = clot)
summary(lmod2)
plot(lmod2)
#(c) Does the time to clot vary according to concentration differently in the two lots?
lmod3 <- lm(invTime ~ log(conc) + lot + log(conc):lot, data = clot)
lmod3 <- lm(invTime ~ log(conc)*lot, data = clot)
summary(lmod3)
anova(lmod3)
#(c) Does the time to clot vary according to concentration differently in the two lots?
lmod3 <- lm(invTime ~ log(conc) + lot + log(conc):lot, data = clot)
lmod3 <- lm(invTime ~ log(conc)*lot, data = clot)
summary(lmod3)
anova(lmod3)
#(d) Check the assumptions of your model using regression diagnostics.
plot(lmod3)
lmod4 <- lm(I(1/time) ~ log(conc) + lot + log(conc):lot, data = clot, subset = c(-18))
summary(lmod4)
anova(lmod4)
#(e) At what percentage concentration is the predicted time the same for the two lots?
#for lottwo
pred_two <- (coef(lmod4)[1] + coef(lmod4)[3]) + (coef(lmod4)[2] + coef(lmod4)[4])*log(clot$conc)
pred_one <- (coef(lmod4)[1]) + (coef(lmod4)[2])*log(clot$conc)
plot(pred_two,pred_one)
abline(0,1)
exp(-coef(lmod4)[3]/coef(lmod4)[4])
#221/7
#The wealth in billions of dollars for 232 billionaires is given in fortune.
data(fortune)
#221/7
#The wealth in billions of dollars for 232 billionaires is given in fortune.
data(fortune)
summary(fortune)
# A, Asia, E, Europe, M, Middle East, O Other, U USA
head(fortune)
#(a) Plot the wealth as a function of age using a different plotting symbol for the
#different regions of the world.
plot(wealth ~ age, pch=as.character(region), fortune)
#(b) Plot the wealth as a function of age with a seperate panel for each region.
require(ggplot2)
ggplot(aes(x=age,y=wealth),data=fortune) + geom_point() + facet_wrap( ~ region)
#(c) Determine a transformation on the response to facilitate linear modeling.
lmod <- lm(wealth ~ age + region, data = fortune)
summary(lmod)
boxcox(lmod)
plot(I(1/wealth) ~ age, pch=as.character(region), fortune)
fortune$rwealth <- 1/fortune$wealth
ggplot(aes(x=age,y=rwealth),data=fortune) + geom_point() + facet_wrap( ~ region)
#hope-less
plot(I(1/wealth) ~ age, pch=as.character(region), fortune)
#(d) What is the relationship of age and region to wealth?
lmod_t <- lm(rwealth ~ age*region, data = fortune, subset = wealth<10)
summary(lmod_t)
#(e) Check the assumptions of your model using appropriate diagnostics
plot(lmod_t)
#221/8
#Ankylosing spondylitis is a chronic form of arthritis. A study was conducted to determine whether daily stretching
#of the hip tissues would improve mobility. The data are found in hips. The flexion angle of the hip before the
#study is a predictor and the flexion angle after the study is the response.
data(hips)
summary(hips)
#(a) Plot the data using different plotting symbols for the treatment and the control status.
plot(faft ~ fbef, pch=as.character(grp), hips)
require(ggplot2)
ggplot(aes(x=fbef,y=faft),data=hips) + geom_point() + facet_wrap( ~ grp)
#(b) Fit a model to determine whether there is a treatment effect.
lmod <- lm(faft ~ fbef + grp, data = hips)
summary(lmod)
#(c) Compute the difference between the flexion before and after and test whether
#this difference varies between treatment and control. Contrast this approach to your previous model.
lmod2 <- lm(I(faft-fbef) ~ grp, data = hips)
summary(lmod2)
t.test(I(faft-fbef) ~ grp, hips, var.equal=TRUE)
hips$f_diff <- hips$faft - hips$fbef
lmod2 <- lm(f_diff ~ grp, data = hips)
#(d) Check for outliers. Explain why we might remove the three cases with fbef less than 90.
#Refit an appropriate model and check for a treatment effect.
plot(lmod2)
confint(lmod3)
#right leg
lmod4 <- lm(I(faft-fbef) ~ grp, data = hips, subset=fbef>90 & side == "right")
summary(lmod4)
#left leg
lmod5 <- lm(I(faft-fbef) ~ grp, data = hips, subset=fbef>90 & side == "left")
summary(lmod5)
hips$fbef_avg <- rep(sapply(1:39,function(a) mean(hips$fbef[hips$person==a])), each = 2)
hips$faft_avg <- rep(sapply(1:39,function(a) mean(hips$faft[hips$person==a])), each = 2)
hips$faft_avg_side <- rep(sapply(1:39,function(a) min(hips$faft[hips$person==a & hips$side=='right'], hips$faft[hips$person==a & hips$side=='left'])),each=2)
#check if it worked
head(hips)
lmod6 <- lm(I(faft_avg-fbef_avg) ~ grp, data = hips, subset=fbef_avg>90 & side == "right")
summary(lmod6)
data(Salaries)
?Salaries
head(Salaries)
summary(Salaries)
pairs(Salaries)
## Kedze nasou ulohou je zistit, ci pohlavie vyznamne vplyva na vysku
## platu, pozrime sa aj na sumar v ramci kazdeho z pohlavi.
by(Salaries, Salaries$sex, summary)
## Pre kazde pohlavie vykreslite boxplot vysky platu.
plot(salary ~ sex, Salaries)
# uzitocne kniznice
library(faraway)
library(car)
data(Salaries)
?Salaries
head(Salaries)
summary(Salaries)
pairs(Salaries)
## Kedze nasou ulohou je zistit, ci pohlavie vyznamne vplyva na vysku
## platu, pozrime sa aj na sumar v ramci kazdeho z pohlavi.
by(Salaries, Salaries$sex, summary)
## Pre kazde pohlavie vykreslite boxplot vysky platu.
plot(salary ~ sex, Salaries)
?Salaries
## Otestujte rovnost strednych hodnot platu muzov a zien za predpokladu
## rovnakej variancie. Interpretujte. Je tento test vhodny?
t.test(salary ~ sex, Salaries, var.equal=TRUE)
## Zostavte linearny regresny model na porovnanie platov muzov a zien.
## Co bude odozva a co prediktor? Urobte rychlu diagnostiku modelu
## a interpretujte jeho koeficienty.
# odozva plat, jediny prediktor pohlavie
moSex = lm(salary ~ sex, data = Salaries)
summary(moSex)
plot(moSex)
cor(Salaries$yrs.since.phd, Salaries$yrs.service)
## Fitnite linearny regresny model s odozvou salary a vsetkymi ostatnymi
## prediktormi, okrem yrs.since.phd. Urobte rychlu diagnostiku
## a interpretujte koeficienty.
moAll = lm(salary ~ yrs.service + rank + discipline + sex,
data = Salaries)
# alebo: moAll = lm(salary ~ . - yrs.since.phd, data = Salaries)
summary(moAll)
# ovela lepsi fit: 44.78%
# signifikancia prediktorov hovoriacich o titule ucitela a jeho odvetvi
# pridanim tychto premennych sa zda, ze pohlavie nie je vyznamne
plot(moAll)
moAll1 = update(moAll, . ~ . -yrs.service)
summary(moAll1)
moAll2 = update(moAll1, . ~ . -sex)
summary(moAll2)
# ponechali sme prediktory rank a discipline
# fit je takmer rovnaky a model je jednoduchsi
plot(moAll2)
# interakcia nie je signifikantna, teda nie je v modeli potrebna
anova(moInter)
## Vzajomne porovnajte vsetky modely (teda model len s pohlavim, model
## so vsetkymi regresormi a vysledny model zo spatnej eliminacie).
anova(moSex, moAll)
# H_0: modely su si podobne
# p-hodnota mensia ako akakolvek "rozumna" hladina vyznamnosti, preto
# zamietame H_0 v prospech H_1
# teda: modely si nie su podobne; vacsi model je lepsi
anova(moSex, moAll2)
# modely si nie su podobne, model moAll2 je lepsi nez moSex
anova(moAll, moAll2)
# porovnanie koeficientov:
moSex$coef
moAll$coef
moAll2$coef
# koeficienty modelov moAll a moAll2 maju rovnake znamienka a prilis
# koeficienty modelov moAll a moAll2 maju rovnake znamienka a prilis
# sa nelisia (teda premenne maju velmi podobny vplyv na rast/pokles
## Urobte zaver.
## Urobte zaver.
# v datach Salaries sme pomocou linearnej regresie mali sledovat, ci je
## Urobte zaver.
# v datach Salaries sme pomocou linearnej regresie mali sledovat, ci je
# zmena v plate profesoriek a profesorov vyznamna
## Urobte zaver.
# v datach Salaries sme pomocou linearnej regresie mali sledovat, ci je
# zmena v plate profesoriek a profesorov vyznamna
# ukazalo sa, ze na vysku platu maju vacsi vplyv ine premenne nez pohlavie
## Urobte zaver.
# v datach Salaries sme pomocou linearnej regresie mali sledovat, ci je
# zmena v plate profesoriek a profesorov vyznamna
# ukazalo sa, ze na vysku platu maju vacsi vplyv ine premenne nez pohlavie
# do buducna by sme odporucali model moAll2, ktory je velmi podobny plnemu
## Urobte zaver.
# v datach Salaries sme pomocou linearnej regresie mali sledovat, ci je
# zmena v plate profesoriek a profesorov vyznamna
# ukazalo sa, ze na vysku platu maju vacsi vplyv ine premenne nez pohlavie
# do buducna by sme odporucali model moAll2, ktory je velmi podobny plnemu
# modelu, no je o cosi jednoduchsi; obsahuje len prediktory hovoriace
## Urobte zaver.
# v datach Salaries sme pomocou linearnej regresie mali sledovat, ci je
# zmena v plate profesoriek a profesorov vyznamna
# ukazalo sa, ze na vysku platu maju vacsi vplyv ine premenne nez pohlavie
# do buducna by sme odporucali model moAll2, ktory je velmi podobny plnemu
# modelu, no je o cosi jednoduchsi; obsahuje len prediktory hovoriace
# o titule ucitela a jeho odvetvi
## Urobte zaver.
# v datach Salaries sme pomocou linearnej regresie mali sledovat, ci je
# zmena v plate profesoriek a profesorov vyznamna
# ukazalo sa, ze na vysku platu maju vacsi vplyv ine premenne nez pohlavie
# do buducna by sme odporucali model moAll2, ktory je velmi podobny plnemu
# modelu, no je o cosi jednoduchsi; obsahuje len prediktory hovoriace
# o titule ucitela a jeho odvetvi
# ak by sme ho chceli este vylepsit, odporucame sa pozriet na vyznamne
## Urobte zaver.
# v datach Salaries sme pomocou linearnej regresie mali sledovat, ci je
# zmena v plate profesoriek a profesorov vyznamna
# ukazalo sa, ze na vysku platu maju vacsi vplyv ine premenne nez pohlavie
# do buducna by sme odporucali model moAll2, ktory je velmi podobny plnemu
# modelu, no je o cosi jednoduchsi; obsahuje len prediktory hovoriace
# o titule ucitela a jeho odvetvi
# ak by sme ho chceli este vylepsit, odporucame sa pozriet na vyznamne
# pozorovania, napr. 44, 250, 365 a pripadne zostavit novy model
## Urobte zaver.
# v datach Salaries sme pomocou linearnej regresie mali sledovat, ci je
# zmena v plate profesoriek a profesorov vyznamna
# ukazalo sa, ze na vysku platu maju vacsi vplyv ine premenne nez pohlavie
# do buducna by sme odporucali model moAll2, ktory je velmi podobny plnemu
# modelu, no je o cosi jednoduchsi; obsahuje len prediktory hovoriace
# o titule ucitela a jeho odvetvi
# ak by sme ho chceli este vylepsit, odporucame sa pozriet na vyznamne
# pozorovania, napr. 44, 250, 365 a pripadne zostavit novy model
# bez nich
library(faraway)
data(sexab,package="faraway")
sexab
#look at the variable for different groups
by(sexab,sexab$csa,summary)
#boxplot for categorical variable
plot(ptsd ~ csa, sexab)
plot(ptsd ~ cpa, pch=as.character(csa), sexab)
#t-test H_0: the two groups have equal mean
#equality of variances is also assumed
t.test(ptsd ~ csa, sexab, var.equal=TRUE)
#create dummy variables for factors
d1 <- ifelse(sexab$csa == "Abused",1,0)
d2 <- ifelse(sexab$csa == "NotAbused",1,0)
#if we add them all to the linear model
# and together with a constant
lmod <- lm(ptsd ~ d1 + d2 , sexab)
sumary(lmod)
#we remove one variable, that will be the base that we compare other variable to
model.matrix(lmod)
lmod <- lm(ptsd ~ d2, sexab)
sumary(lmod)
#in this regression parameters are directly means of different groups
lmod <- lm(ptsd ~ d1 + d2 -1, sexab)
sumary(lmod)
lmod <- lm(ptsd ~ cpa + csa, sexab)
sumary(lmod)
abline(lmod$coeff[1],lmod$coeff[2])
abline(lmod$coeff[1]+lmod$coeff[3],lmod$coeff[2])
#we may want to recode the factor variable, so that the reference is picked
#(and not set according to alphabet)
class(sexab$csa)
sexab$csa <- relevel(sexab$csa, ref="NotAbused")
lmod <- lm(ptsd ~ csa, sexab)
sumary(lmod)
#interaction term?
lmod4 <- lm(ptsd ~ cpa+csa+cpa:csa,sexab)
sumary(lmod4)
model.matrix(lmod4)
plot(ptsd ~ cpa, sexab, pch=as.numeric(csa))
abline(3.96, 0.764)
abline(3.96+6.86, 0.764-0.314,lty=2)
lmod3 <- lm(ptsd ~ cpa+csa,sexab)
sumary(lmod3)
plot(ptsd ~ cpa, sexab, pch=as.numeric(csa))
abline(3.98, 0.551)
abline(3.98+6.27, 0.551, lty=2)
confint(lmod3)[3,]
plot(fitted(lmod3),residuals(lmod3),pch=as.numeric(sexab$csa),  xlab="Fitted",ylab="Residuals")
lmod1 <- lm(ptsd ~ cpa,sexab)
sumary(lmod1)
plot(ptsd ~ cpa, sexab, pch=as.numeric(csa))
abline(3.98, 0.551)
abline(3.98+6.27, 0.551, lty=2)
confint(lmod3)[3,]
plot(fitted(lmod3),residuals(lmod3),pch=as.numeric(sexab$csa),  xlab="Fitted",ylab="Residuals")
lmod1 <- lm(ptsd ~ cpa,sexab)
plot(ptsd ~ cpa, sexab, pch=as.numeric(csa))
abline(3.96, 0.764)
abline(3.96+6.86, 0.764-0.314,lty=2)
lmod3 <- lm(ptsd ~ cpa+csa,sexab)
sumary(lmod3)
plot(ptsd ~ cpa, sexab, pch=as.numeric(csa))
abline(3.98, 0.551)
abline(3.98+6.27, 0.551, lty=2)
confint(lmod3)[3,]
plot(fitted(lmod3),residuals(lmod3),pch=as.numeric(sexab$csa),  xlab="Fitted",ylab="Residuals")
lmod1 <- lm(ptsd ~ cpa,sexab)
sumary(lmod1)
#centering is important in models with interactions!
data(whiteside,package="MASS")
require(ggplot2)
ggplot(aes(x=Temp,y=Gas),data=whiteside)+geom_point()+facet_grid(~ Insul)+geom_smooth(method="lm")
lmod <- lm(Gas ~ Temp*Insul, whiteside)
sumary(lmod)
mean(whiteside$Temp)
whiteside$ctemp <- whiteside$Temp - mean(whiteside$Temp)
lmodc <- lm(Gas ~ ctemp*Insul, whiteside)
sumary(lmodc)
#sex-life of fruitflies
data(fruitfly,package="faraway")
plot(longevity ~ thorax, fruitfly, pch=unclass(activity))
legend(0.63,100,levels(fruitfly$activity),pch=1:5)
?fruitfly
#contrasts
contr.treatment(4)
contr.helmert(4)
contr.helmert(4)[,1]
sum(contr.helmert(4)[,1] * contr.helmert(4)[,2])
sum(contr.helmert(4)[,1] * contr.helmert(4)[,3])
sum(contr.helmert(4)[,2] * contr.helmert(4)[,3])
contr.sum(4)
sum(contr.sum(4)[,2] * contr.sum(4)[,3])
?contr.sum
contrasts(sexab$csa) <- contr.sum(2)
sumary(lm(ptsd ~ csa, sexab))
contr.sum(2)
x <- 1:99
y <- c(8, 18, 80, 88, 85, 84, 89, 81, 87, 86, 83, 82,
11, 15, 50, 58, 55, 54, 59, 51, 57, 56, 53, 52,
5, 40, 48, 45, 44, 49, 41, 47, 46, 43, 42,
14, 4,
9, 19, 90, 98, 95, 94, 99, 91, 97, 96, 93, 92,
1,
7, 17, 70, 78, 75, 74, 79, 71, 77, 76, 73, 72,
6, 16, 60, 68, 65, 64, 69, 61, 67, 66, 63, 62,
10, 30, 38, 35, 34, 39, 31, 37, 36, 33, 32,
3, 12, 20, 28, 25, 24, 29, 21, 27, 26, 23, 22,
2,
13)
plot(x,y)
