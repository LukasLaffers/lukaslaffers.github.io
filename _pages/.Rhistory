group = factor(names(split_obj), levels = 1:4),
perc_self = 100 * sapply(split_obj, function(x) ecdf(data[,"obj"])(mean(x[,"self"]))),
perc_obj = 100 * sapply(split_obj, function(x) ecdf(data[,"obj"])(mean(x[,"obj"])))
)
p_obj <- ggplot(df_obj, aes(x = group)) +
geom_line(aes(y = perc_obj, group = 1, color = "Objective")) +
geom_point(aes(y = perc_obj, color = "Objective")) +
geom_line(aes(y = perc_self, group = 1, color = "Self-report")) +
geom_point(aes(y = perc_self, color = "Self-report")) +
labs(x = "Group (objective)", y = "Percentile (%)", color = "") +
theme(legend.position = "bottom")
# Quartiles based on first column (self)
q_self <- quantile(data[,1], probs = c(0.25, 0.5, 0.75))
groups_self <- cut(data[,1], breaks = c(-Inf, q_self[1], q_self[2], q_self[3], Inf), labels = FALSE)
split_self <- split(as.data.frame(data), groups_self)
df_self <- data.frame(
group = factor(names(split_self), levels = 1:4),
perc_self = 100 * sapply(split_self, function(x) ecdf(data[,"self"])(mean(x[,"self"]))),
perc_obj = 100 * sapply(split_self, function(x) ecdf(data[,"self"])(mean(x[,"obj"])))
)
p_self <- ggplot(df_self, aes(x = group)) +
geom_line(aes(y = perc_obj, group = 1, color = "Objective")) +
geom_point(aes(y = perc_obj, color = "Objective")) +
geom_line(aes(y = perc_self, group = 1, color = "Self-report")) +
geom_point(aes(y = perc_self, color = "Self-report")) +
labs(x = "Group (self-report)", y = "Percentile (%)", color = "") +
theme(legend.position = "bottom")
grid.arrange(p_obj, p_self, ncol = 2)
library(MASS)
library(ggplot2)
library(gridExtra)
n <- 1000
mu <- c(0, 0)
rho <- 0.19
sigma <- matrix(c(1, rho, rho, 1), nrow = 2)
set.seed(565)
data <- mvrnorm(n = n, mu = mu, Sigma = sigma)
#n <- 1000
#data = matrix(0.0, nrow=n, ncol=2)
#data[,1] = rnorm(n)
#data[,2] = data[,1] + 4*rnorm(n)
#colnames(data) <- c("self","obj")
#cor(data[,1],data[,2])
colnames(data) <- c("self","obj")
data[,1] <- data[,1] + 0.5
# Quartiles based on second column (obj)
q_obj <- quantile(data[,2], probs = c(0.25, 0.5, 0.75))
groups_obj <- cut(data[,2], breaks = c(-Inf, q_obj[1], q_obj[2], q_obj[3], Inf), labels = FALSE)
split_obj <- split(as.data.frame(data), groups_obj)
df_obj <- data.frame(
group = factor(names(split_obj), levels = 1:4),
perc_self = 100 * sapply(split_obj, function(x) ecdf(data[,"obj"])(mean(x[,"self"]))),
perc_obj = 100 * sapply(split_obj, function(x) ecdf(data[,"obj"])(mean(x[,"obj"])))
)
p_obj <- ggplot(df_obj, aes(x = group)) +
geom_line(aes(y = perc_obj, group = 1, color = "Objective")) +
geom_point(aes(y = perc_obj, color = "Objective")) +
geom_line(aes(y = perc_self, group = 1, color = "Self-report")) +
geom_point(aes(y = perc_self, color = "Self-report")) +
labs(x = "Group (objective)", y = "Percentile (%)", color = "") +
theme(legend.position = "bottom")
# Quartiles based on first column (self)
q_self <- quantile(data[,1], probs = c(0.25, 0.5, 0.75))
groups_self <- cut(data[,1], breaks = c(-Inf, q_self[1], q_self[2], q_self[3], Inf), labels = FALSE)
split_self <- split(as.data.frame(data), groups_self)
df_self <- data.frame(
group = factor(names(split_self), levels = 1:4),
perc_self = 100 * sapply(split_self, function(x) ecdf(data[,"self"])(mean(x[,"self"]))),
perc_obj = 100 * sapply(split_self, function(x) ecdf(data[,"self"])(mean(x[,"obj"])))
)
p_self <- ggplot(df_self, aes(x = group)) +
geom_line(aes(y = perc_obj, group = 1, color = "Objective")) +
geom_point(aes(y = perc_obj, color = "Objective")) +
geom_line(aes(y = perc_self, group = 1, color = "Self-report")) +
geom_point(aes(y = perc_self, color = "Self-report")) +
labs(x = "Group (self-report)", y = "Percentile (%)", color = "") +
theme(legend.position = "bottom")
grid.arrange(p_obj, p_self, ncol = 2)
library(MASS)
library(ggplot2)
library(gridExtra)
n <- 1000
mu <- c(0, 0)
rho <- 0.19
sigma <- matrix(c(1, rho, rho, 1), nrow = 2)
set.seed(565)
data <- mvrnorm(n = n, mu = mu, Sigma = sigma)
#n <- 1000
#data = matrix(0.0, nrow=n, ncol=2)
#data[,1] = rnorm(n)
#data[,2] = data[,1] + 4*rnorm(n)
#colnames(data) <- c("self","obj")
#cor(data[,1],data[,2])
colnames(data) <- c("self","obj")
#add a shift(?)
shift <- 0
data[,1] <- data[,1] + shift
# Quartiles based on second column (obj)
q_obj <- quantile(data[,2], probs = c(0.25, 0.5, 0.75))
groups_obj <- cut(data[,2], breaks = c(-Inf, q_obj[1], q_obj[2], q_obj[3], Inf), labels = FALSE)
split_obj <- split(as.data.frame(data), groups_obj)
df_obj <- data.frame(
group = factor(names(split_obj), levels = 1:4),
perc_self = 100 * sapply(split_obj, function(x) ecdf(data[,"obj"])(mean(x[,"self"]))),
perc_obj = 100 * sapply(split_obj, function(x) ecdf(data[,"obj"])(mean(x[,"obj"])))
)
p_obj <- ggplot(df_obj, aes(x = group)) +
geom_line(aes(y = perc_obj, group = 1, color = "Objective")) +
geom_point(aes(y = perc_obj, color = "Objective")) +
geom_line(aes(y = perc_self, group = 1, color = "Self-report")) +
geom_point(aes(y = perc_self, color = "Self-report")) +
labs(x = "Group (objective)", y = "Percentile (%)", color = "") +
theme(legend.position = "bottom")
# Quartiles based on first column (self)
q_self <- quantile(data[,1], probs = c(0.25, 0.5, 0.75))
groups_self <- cut(data[,1], breaks = c(-Inf, q_self[1], q_self[2], q_self[3], Inf), labels = FALSE)
split_self <- split(as.data.frame(data), groups_self)
df_self <- data.frame(
group = factor(names(split_self), levels = 1:4),
perc_self = 100 * sapply(split_self, function(x) ecdf(data[,"self"])(mean(x[,"self"]))),
perc_obj = 100 * sapply(split_self, function(x) ecdf(data[,"self"])(mean(x[,"obj"])))
)
p_self <- ggplot(df_self, aes(x = group)) +
geom_line(aes(y = perc_obj, group = 1, color = "Objective")) +
geom_point(aes(y = perc_obj, color = "Objective")) +
geom_line(aes(y = perc_self, group = 1, color = "Self-report")) +
geom_point(aes(y = perc_self, color = "Self-report")) +
labs(x = "Group (self-report)", y = "Percentile (%)", color = "") +
theme(legend.position = "bottom")
grid.arrange(p_obj, p_self, ncol = 2)
#load library with all datasets used in Faraway's book
library(faraway)
data(pima, package="faraway")
#look at the header
head(pima)
#and summary statistics
summary(pima)
#sort the data on diastolic pressure
sort(pima$diastolic)
#therefore, we replace these zeros with NA (not available) values
pima$diastolic[pima$diastolic == 0]  <- NA
pima$glucose[pima$glucose == 0] <- NA
pima$triceps[pima$triceps == 0]  <- NA
pima$insulin[pima$insulin == 0] <- NA
pima$bmi[pima$bmi == 0] <- NA
#the following values are cathegorical, not numerical
pima$test <- factor(pima$test)
#we may be interested in summary statistics
summary(pima$test)
#we make use of descriptive labels
levels(pima$test) <- c("negative","positive")
summary(pima)
#there are different ways of visualising the distribution of data
#histogram is one of those. the number and width of the bins is set automatically, but can be easily modified
hist(pima$diastolic,xlab="Diastolic",main="")
#another way is to use a smoothed density. the amount of smoothing is set automatically, but can be amended
plot(density(pima$diastolic,na.rm=TRUE),main="")
#we may also as well plot the sorted data, here we see individual points (!)
plot(sort(pima$diastolic),ylab="Sorted Diastolic")
#we may ask if there's any relationship between diastolic pressure and diabetes
plot(diabetes ~ diastolic,pima)
#if the second variable is cathegorical, it produces box plot
plot(diabetes ~ test,pima)
#throughout this course, we will make use of advanced graphic library ggplot2
require(ggplot2)
ggplot(pima,aes(x=diastolic))+geom_histogram()
ggplot(pima,aes(x=diastolic))+geom_density()
ggplot(pima,aes(x=diastolic,y=diabetes))+geom_point()
ggplot(pima,aes(x=diastolic,y=diabetes,shape=test))+geom_point()+theme(legend.position = "top", legend.direction = "horizontal")
ggplot(pima,aes(x=diastolic,y=diabetes)) + geom_point(size=1) + facet_grid(~ test)
#position of manilius crater on the moon (1750 Tobias Mayer)
data(manilius, package="faraway")
head(manilius)
#how did Mayer solve this problem?
#data was divided into three groups so that the observations were "similar in some respect"
(moon3 <- aggregate(manilius[,1:3],list(manilius$group), sum))
#we sum equations in these 3 groups and solve a system of 3 equations and 3 unknowns
solve(cbind(9,moon3$sinang,moon3$cosang), moon3$arc)
#this is not very far from the result of linear regression coefficients
#(we still don't actually kno, what they are)
lmod <- lm(arc ~ sinang + cosang, manilius)
coef(lmod)
summary(lmod)
#how did Mayer choose the groups?
ggplot(manilius,aes(x=sinang,y=cosang)) + geom_point(size=1) + facet_grid(~ group)
ggplot(manilius,aes(x=sinang,y=cosang)) + geom_point(size=1)
#linear regression mechanically (will be explained next week)
X <- cbind(1,manilius[,2],manilius[,3])
Y <- manilius[,1]
solve(t(X)%*%X) %*% t(X) %*% Y
data(GaltonFamilies, package="HistData")
plot(childHeight ~ midparentHeight, GaltonFamilies)
lmod <- lm(childHeight ~ midparentHeight, GaltonFamilies)
coef(lmod)
abline(lmod)
(beta <- with(GaltonFamilies, cor(midparentHeight, childHeight) * sd(childHeight) / sd(midparentHeight)))
(alpha <- with(GaltonFamilies, mean(childHeight) - beta * mean(midparentHeight)))
(beta1 <- with(GaltonFamilies, sd(childHeight) / sd(midparentHeight)))
(alpha1 <- with(GaltonFamilies, mean(childHeight) - beta1 * mean(midparentHeight)))
abline(alpha1, beta1, lty=2)
-  14.10.2025  ~~13:50~~ <span style="color:red">**14:10**</span> – 15:25
# --- recap-example ---------------------------------------------------------
# (kumulatívna distribučná funkcia: hod dvomi kockou)
x <- 0:12+1
plot(x, cumsum(c(0,(1/36)*c(1,2,3,4,5,6,5,4,3,2,1),0)), type="s",
xlab = expression(x),
ylab = expression(P(X <= x)),
main = "Kumulatívna distribučná funkcia: hod dvomi kockou")
points(2:12,cumsum((1/36)*c(1,2,3,4,5,6,5,4,3,2,1)),pch=19)
points(2:12,cumsum(c(0,(1/36)*c(1,2,3,4,5,6,5,4,3,2))))
# --- recap-rand ------------------------------------------------------------
par(mfrow=c(1,1))
set.seed(30)
x1 <- rnorm(10000,0,0.7)
x2 <- rnorm(10000,5,1.5)
x3 <- rnorm(10000,1,0.5)
dens <- density(c(x1,x2,x3))
plot(dens$x, dens$y, type="l",
xlab = expression(x),
ylab = expression(f[X](x)),
main = "Funkcia hustoty")
# --- recap-apply -----------------------------------------------------------
ff <- function(x) sum(c(x1,x2,x3)<x)/30000
yy <- sapply(dens$x,ff)
plot(dens$x,yy,type="l",
xlab = expression(t),
ylab = expression(P(X <= t)),
main = "Kumulatívna distribučná funkcia")
# --- recap-dens ------------------------------------------------------------
plot(dens$x, dens$y, type="l",
xlab = expression(x),
ylab = expression(f[X](x)),
main = "Funkcia hustoty")
value1 <- 2
value2 <- 6
# Lower and higher indices on the X-axis
l <- min(which(dens$x >= value1))
h <- max(which(dens$x < value2))
polygon(c(dens$x[c(l, l:h, h)]),
c(0, dens$y[l:h], 0),
col = "blue")
ff <- function(x) sum(c(x1,x2,x3)<x)/30000
yy <- sapply(dens$x,ff)
plot(dens$x,yy,type="l",
xlab = expression(t),
ylab = expression(F[X](t) == P(X <= t)),
main = "Kumulatívna distribučná funkcia")
points(value1,ff(value1),col="blue")
points(value2,ff(value2),col="blue")
arrows(x0=value2,y0=ff(value2),x1=value2,y1=ff(value1),col="blue",code=3)
abline(a=ff(value1),b=0,col="blue")
abline(a=ff(value2),b=0,col="blue")
# --- recap-iq --------------------------------------------------------------
x <- seq(50,150,by=1)
y <- dnorm(x,100,15)
plot(x, y, type="l",
xlab = expression(x),
ylab = expression(f[X](x)),
main = "Funkcia hustoty IQ")
value1 <- 130
value2 <- 1000
# Lower and higher indices on the X-axis
l <- min(which(x >= value1))
h <- max(which(x < value2))
polygon(c(x[c(l, l:h, h)]),
c(0, y[l:h], 0),
col = "red")
# --- recap-mzdy ------------------------------------------------------------
x <- seq(0,5,by=0.01)
y <- dlnorm(x, meanlog = 0, sdlog = 1, log = FALSE)
plot(x, y, type="l",
xlab = expression(x),
ylab = expression(f[X](x)),
ylim=c(0,1),
main = "Funkcia hustoty, medián a stredná hodnota")
mm <- exp(0.5)
med <- qlnorm(0.5, meanlog = 0, sdlog = 1, lower.tail = TRUE, log.p = FALSE)
points(med,0,pch=19,col="red")
abline(v=med, col="red", lty=2)
points(mm,0,pch=19,col="red")
abline(v=mm, col="red")
# --- recap-fhus -----------------------------------------------------------
plot(x, y, type="l",
xlab = expression(x),
ylab = expression(f[X](x)),
ylim=c(0,1),
main = "Funkcia hustoty, 10%ný a 90%ný kvantil")
mm <- exp(0.5)
q10 <- qlnorm(0.1, meanlog = 0, sdlog = 1, lower.tail = TRUE, log.p = FALSE)
q90 <- qlnorm(0.9, meanlog = 0, sdlog = 1, lower.tail = TRUE, log.p = FALSE)
points(q10,0,pch=19,col="blue")
abline(v=q10, col="blue", lty=2)
points(q90,0,pch=19,col="blue")
abline(v=q90, col="blue", lty=2)
# --- recap-demo -----------------------------------------------------------
library(ISwR)
#set random seed
set.seed(3214)
#generate sample of size 50 from N(0,1)
x <- rnorm(50)
#look at the histogram
hist(x,freq=F)
lines(seq(-3,3,0.01),dnorm(seq(-3,3,0.01)))
# --- recap-mean -----------------------------------------------------------
#sample mean
mean(x)
sum(x)/length(x)
# --- recap-var ------------------------------------------------------------
#sample variance
var(x)
sum((x-mean(x))^2)/(length(x)-1)
#sample standard deviation
sd(x)
sqrt(sum((x-mean(x))^2)/(length(x)-1))
# --- recap-median ---------------------------------------------------------
#sample median
median(x)
sort(x)[round(length(x)/2)]
#quantile
quantile(x)
pvec <- seq(0,1,0.1)
pvec
#look at different quantiles at once
quantile(x,pvec)
# --- recap-simul ----------------------------------------------------------
nSim <- 1000000
X <- rnorm(nSim)
1 - mean( (X > -1.96) * (X < 1.96) )
library(randomForest)
# Example:
# rtree <- randomForest(y ~ ., data = your_data, ntree = 500)
tree1 <- getTree(rtree, k = 1, labelVar = TRUE)
# Example:
rtree <- randomForest(y ~ ., data = your_data, ntree = 500)
cfHt <- causalForest(Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
data = df,
treatment = W,
ncov_sample=10,
ncolx = 10,
num.trees = ntree,
split.Rule = "fit", cv.option = "fit",
split.Honest = TRUE, cv.Honest = TRUE, split.Bucket = TRUE,
bucketNum = 5,
bucketMax = 200,
minsize = 20, propensity = 0.5)
library(randomForest)
cfHt <- causalForest(Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
data = df,
treatment = W,
ncov_sample=10,
ncolx = 10,
num.trees = ntree,
split.Rule = "fit", cv.option = "fit",
split.Honest = TRUE, cv.Honest = TRUE, split.Bucket = TRUE,
bucketNum = 5,
bucketMax = 200,
minsize = 20, propensity = 0.5)
library(randomForest)
library(grf)
library(htetree)
library(rpart)
library("htetree")
library("rpart")
library("rpart.plot")
library("formula.tools")
library("caret")
library("ggridges")
cfHt <- causalForest(Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
data = df,
treatment = W,
ncov_sample=10,
ncolx = 10,
num.trees = ntree,
split.Rule = "fit", cv.option = "fit",
split.Honest = TRUE, cv.Honest = TRUE, split.Bucket = TRUE,
bucketNum = 5,
bucketMax = 200,
minsize = 20, propensity = 0.5)
n <- 500
p <- 10
X <- matrix(rnorm(n * p), n, p)
W <- rbinom(n, 1, 0.5)
#Y <- pmax(X[, 1], 0) * W + X[, 2] + pmin(X[, 3], 0) + rnorm(n)
#Y <- X[, 1] * W + X[, 2] + pmin(X[, 3], 0) + rnorm(n)
Y <- X[, 3] * W + rnorm(n)
cfHt <- causalForest(Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
data = df,
treatment = W,
ncov_sample=10,
ncolx = 10,
num.trees = ntree,
split.Rule = "fit", cv.option = "fit",
split.Honest = TRUE, cv.Honest = TRUE, split.Bucket = TRUE,
bucketNum = 5,
bucketMax = 200,
minsize = 20, propensity = 0.5)
n <- 500
p <- 10
X <- matrix(rnorm(n * p), n, p)
W <- rbinom(n, 1, 0.5)
#Y <- pmax(X[, 1], 0) * W + X[, 2] + pmin(X[, 3], 0) + rnorm(n)
#Y <- X[, 1] * W + X[, 2] + pmin(X[, 3], 0) + rnorm(n)
Y <- X[, 3] * W + rnorm(n)
ntree <- 100
cfHt <- causalForest(Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
data = df,
treatment = W,
ncov_sample=10,
ncolx = 10,
num.trees = ntree,
split.Rule = "fit", cv.option = "fit",
split.Honest = TRUE, cv.Honest = TRUE, split.Bucket = TRUE,
bucketNum = 5,
bucketMax = 200,
minsize = 20, propensity = 0.5)
df <- data.frame(Y,X,W)
ntree <- 100
cfHt <- causalForest(Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
data = df,
treatment = W,
ncov_sample=10,
ncolx = 10,
num.trees = ntree,
split.Rule = "fit", cv.option = "fit",
split.Honest = TRUE, cv.Honest = TRUE, split.Bucket = TRUE,
bucketNum = 5,
bucketMax = 200,
minsize = 20, propensity = 0.5)
tree1 <- getTree(cfHt, k = 1, labelVar = TRUE)
head(cfHt$trees[[1]])
head(cfHt$trees[[2]])
plot(cfHt$trees[[2]])
cfHt$trees[[2]
]
cfHt$trees[[2]]
cfHt$trees[[3]]
cfHt$trees[[4]]]
cfHt$trees[[4]]
cfHt$trees[[5]]
a <- cfHt$trees[[5]]
a$frame
a$where
class(a)
treeInfo(a)
get_tree(a)
get_tree(a,1)
?get_tree
importance(cfHt)
importance(cfHt$trees[[1]])
importance(cfHt$trees[[5]])
aa
a
hte_plot(a)
hte_plot(cfHt$trees[[5]])
cfHt$trees[[5]]
a <- 0.1
m <- c(a, 1-a,1,0)
P <- matrix(m,2,byrow=TRUE)
Q <-  eigen(P)$vectors
iQ <- solve(eigen(P)$vectors)
c1 <- sqrt(2)/2
c2 <- 1/(sqrt((a-1)^2+1))
Q2 <- matrix(c(c1, (a-1)*c2, c1, c2), 2,byrow=TRUE)
iQ2 <- matrix(c(1/(c1*(2-a)), (1-a)/((2-a)*c1), 1/((a-2)*c2), 1/((2-a)*c2)), 2, byrow=TRUE)
Lambda = matrix(c(1,0,0,a-1),2,byrow=TRUE)
Q2 %*% Lambda^4 %*% iQ2
P %*% P %*% P %*% P
n = 4
Pn = matrix(c(
(1 - (a-1)^(n+1))/(2-a),
(1 - a + (a-1)^(n+1))/(2-a),
(1 - (a-1)^(n))/(2-a),
(1 - a + (a-1)^(n))/(2-a)
),2,byrow=TRUE)
Pn
Q %*% Lambda^4 %*% iQ
a <- 0.1
m <- c(a, 1-a,1,0)
P <- matrix(m,2,byrow=TRUE)
J <- matrix(c(1,0,0,a-1),2,byrow=TRUE)
S  <- matrix(c(1,a-1,1,1),2,byrow=TRUE)
iS <- matrix(c(1/(2-a),(a-1)/(a-2),1/(a-2),1/(2-a)),2,byrow=TRUE)
S %*% J %*% iS
P
S %*% J^4 %*% iS
P %*% P %*% P %*% P
a <- 0.1
m <- c(a, 1-a,1,0)
P <- matrix(m,2,byrow=TRUE)
Q
Q
c
c
n
P
Q
c1
c2
eigen(P)
c1
c2
J <- matrix(c(1,0,0,a-1),2,byrow=TRUE)
S  <- matrix(c(1,a-1,1,1),2,byrow=TRUE)
iS <- matrix(c(1/(2-a),(a-1)/(a-2),1/(a-2),1/(2-a)),2,byrow=TRUE)
S %*% J %*% iS
P
S %*% J^4 %*% iS
P %*% P %*% P %*% P
S %*% J^4 %*% iS
P %*% P %*% P %*% P
S %*% J %*% iS
P
